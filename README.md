# ДАШБОРД

## Установка requirements
Для работы проекта необходимы библиотеки, указанные в requirements:
```
pip install -r requirements.txt
```
## Запуск проекта
Перейдите в корневую папку.
Для запуска проекта нужно выполнить команду:
```
streamlit run dashboard.py
```
## Принцип работы проекта

### Что подаётся на вход
На вход подаётся файл лога в формате *.json*, которые выглядит:
```json
[
{
        "selected_role":"Студент",
        "campus":"Нижний Новгород",
        "education_level":"Бакалавриат",
        "question_category":"Наука",
        "user_filters":[
            "Нижний Новгород",
            "бакалавриат"
        ],
        "question_filters":[
            "Наука"
        ],
        "question":"Для чего нужно подробное изучение науки, проведение исследований, экспериментов, участвие в каких-то конкурсах, если",
        "answer":"Я понял ваш вопрос. Вы хотите узнать, почему необходимо детальное изучение науки...",
        "ground_truth":"Подробное изучение науки, проведение исследований...",
        "contexts":[
            "Конкурсы игранты НИУВШЭ Конкурсы и гранты НИУ ВШЭ для поддержки научных исследований...",
            "60 тыс. знаков, включая пробелы. Рекомендуемый шрифт – Times New Roman...",
            "ную конкурсную работу повторно. Процедура оценки конкурсных работ...",
            "предметным областям, предусмотренным для модуля Major в Образовательном стандарте НИУ ВШЭ..."
        ],
        "source":"giga",
        "rating":"good",
        "response_time":3.517504,
        "context_recall":0.0833333333,
        "context_precision":0.0506935875,
        "answer_correctness_literal":36.1101406715,
        "answer_correctness_neural":0.7597621083
    },
]
```
### Как запускать метрики
Для запуска необходимо запустить два Jupyter Notebook:
hackaton_metrics1.ipynb
hackaton_metrics2.ipynb

В первом файле просчитывается основные метрики и преобразуется входные данные.
Во втором файле просчитывается дополнительная метрика (может долго работать).

### Какие метрики использованы
Стандартные метрики:
- rouge
- bleu
- chrf
- bertscore


Наша специальная метрика:
- Hallucination Metric
  - Semantic Consistency (оценивает семантическую согласованность между контекстом и ответом модели);
  - Factual Accuracy (проверяет фактологическую точность ответа относительно контекста);
  - Tag Relevance (оценивает соответствие тегов ответа эталонным тегам)
  - Context Coverage (анализирует покрытие ключевых слов из ответа в контексте)
 
Hallucination Metric = 0.3 * Semantic Consistency + 0.4 * Factual Accuracy + 0.2 * Tag Relevance + 0.1 * Context Coverage
